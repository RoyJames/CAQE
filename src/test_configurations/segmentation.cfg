#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
A general pairwise (e.g. A is better than B) configuration for evaluating overall quality
of a set of audio stimuli.
"""
import os
# ---------------------------------------------------------------------------------------------
# TESTING VARIABLES
TEST_TYPE = 'segmentation'
STIMULUS_ORDER_RANDOMIZED = False
TEST_CONDITION_ORDER_RANDOMIZED = True
AUDIO_CODEC = 'mp3'

# ---------------------------------------------------------------------------------------------
# MECHANICAL TURK VARIABLES

MTURK_TITLE = 'Marking Boundaries between Parts of a Song'
MTURK_DESCRIPTION = 'Listening to a few audio clips from different songs, ' \
                    'then marking boundaries between parts of a song based on your subjective judgment.'

# ---------------------------------------------------------------------------------------------
# FRONT-END VARIABLES
TEST_TIMEOUT_SEC = 60.
PREVIEW_HTML = """
    <p>This listening task aims at collecting the <b>boundaries timings</b> between parts of a song.</p>

    <p>During this task, you will be asked to listen for <b>when</b> does a part of a song changes to another.</p>

    <p>The expected total duration of the test is 10-15 minutes.</p>

    <p>However, if this is your first HIT in this group, there will also be additional surveys and training sessions, which
    the expected total duration of the first HIT is 15-20 minutes. Because this first HIT takes longer than
    the rest of the HITs in this group, you will be given an additional $0.30 bonus.</p>
    """

# ---------------------------------------------------------------------------------------------
# DEFAULT CONDITION AND TEST-SPECIFIC VARIABLES
#   (These will be configured for each condition and saved in the database)
test_title = 'Task: Mark the <audio_event>'

first_task_introduction_html = """
    <p>This listening task aims at collecting the <b>boundaries timings</b> between parts of a song.</p>

    <p>During this task, you will be asked to listen for <b>when</b> does a part of a song changes to another.
    Lastly, at the end, there will be a short survey which you will only have to fill out for the first HIT you
    complete.</p>
    """

introduction_html = """
    <p>This listening task aims at collecting the <b>boundaries timings</b> between parts of a song.</p>

    <p>During this task, you will be asked to listen for <b>when</b> does a part of a song changes to another.
    </p>
    """

training_instructions_html = """
    <p><audio_event_explanation></p>

    <p>Instructions:
    <ol>
    <li>If you have not done so already, set the volume of your headphones/speakers so that
    it's comfortable. The volume should be the same level when you listen to music leisurely.
    (the volume shouldn't be changed later on).</li>
    <li>Watch the <b>instruction video</b>.</li>
    </ol>
    </p>
    """

evaluation_instructions_html = """
    <p>
        <ol type="1">
            <li>Click the Play/Pause button below to start a <b>first full</b> listening of the music clip.
            Other buttons are <b>disabled</b> before finishing the first full listening of the music clip.
            </li>
            <li>After listening to the clip, you can click on the <b>Boundary Selection Slider</b> to select where
            the music clip changed its part.
            </li>
            <li>You can use the <b>Audio Progress Bar</b> to navigate to different places in the music clip to listen
            to the clip in details.
            </li>
            <li>You cal also listen to your selected boundary by clicking the <b>Check selection</b> button. The
            playback will play from just before your marking til the a short amount after your marking.
            </li>
            <li>If you are satisfied with your marking, hit the <b>Mark slider position</b> button. If you did not heard
            a change of parts within the music clip, hit the <b>No change heard</b> button. You can only go to the next
            trial by clicking on <b>Next Trial</b> button after hitting either the <b>Mark slider position</b> or
            <b>No change heard</b> button.
            </li>
        </ol>
    </p>

    """

batch = 0
num_audio_files = 10

if batch == 0:
    num_test_sets = 25
else:
    num_test_sets = 24


references = (('Reference', 'The reference signal to which test signals are compared.'),)

# The audio event description
audio_events = ['<b>Boundaries between Parts of a Song</b>', ]

# Descriptions of the quality scales
audio_event_explanations = [
    'The goal of the task is to gather timing data on when does one part of a song changes to another. '
    'The audio clips are snippets (random fragments) from songs selected from a variety of genres. '
    'There is no definite rules or definitions to when a part of a song changes to another. '
    'The length for a part of a song could range from 5 to over 30 seconds.', ]

# ---------------------------------------------------------------------------------------------
# TRAINING EXAMPLES FOR PARTICIPANTS
# These are the reference examples for the training examples
# List entries must be dicts composed as {<reference_name>: <example_url>, ...}

# These are the quality examples.
# List entries should be dicts composed as {<description>: <example_url>, ...}

instruction_videos = ['https://dl.dropboxusercontent.com/u/4893373/videos/tutorial_video',]

TESTS = []
conditions = []
for audio_event, audio_event_explanation, instruction_video in zip(audio_events,
                                                                   audio_event_explanations,
                                                                   instruction_videos
                                                                   ):
    test_cfg_vars = {}
    test_cfg_vars['references'] = references

    test_cfg_vars['instruction_video'] = instruction_video

    test_cfg_vars['test_title'] = test_title
    test_cfg_vars['test_title'] = test_cfg_vars['test_title'].replace('<audio_event>', audio_event)

    test_cfg_vars['introduction_html'] = introduction_html
    test_cfg_vars['introduction_html'] = test_cfg_vars['introduction_html'].replace('<audio_event>', audio_event)
    test_cfg_vars['introduction_html'] = test_cfg_vars['introduction_html'].replace('<audio_event_explanation>', audio_event_explanation)

    test_cfg_vars['first_task_introduction_html'] = first_task_introduction_html
    test_cfg_vars['first_task_introduction_html'] = test_cfg_vars['first_task_introduction_html'].replace('<audio_event>', audio_event)
    test_cfg_vars['first_task_introduction_html'] = test_cfg_vars['first_task_introduction_html'].replace('<audio_event_explanation>', audio_event_explanation)

    test_cfg_vars['training_instructions_html'] = training_instructions_html
    test_cfg_vars['training_instructions_html'] = test_cfg_vars['training_instructions_html'].replace('<audio_event>', audio_event)
    test_cfg_vars['training_instructions_html'] = test_cfg_vars['training_instructions_html'].replace('<audio_event_explanation>', audio_event_explanation)

    test_cfg_vars['evaluation_instructions_html'] = evaluation_instructions_html
    test_cfg_vars['evaluation_instructions_html'] = test_cfg_vars['evaluation_instructions_html'].replace('<audio_event>', audio_event)
    test_cfg_vars['evaluation_instructions_html'] = test_cfg_vars['evaluation_instructions_html'].replace('<audio_event_explanation>', audio_event_explanation)

    test = {'test_config_variables': test_cfg_vars,
            'condition_groups': []}

    for i in range(1, num_test_sets + 1):
        # THE AUDIO STIMULUS FILES
        group_data = {
            'reference_files': [['Reference', 'seg%02d_%02d_10.mp3' % (batch, i), ]],
            # 'reference_files': [['Reference', 'segtest%02d_01.wav' % i, ]],
            'stimulus_files': []
        }
        # if i == num_test_sets:
        #     if batch == 0:
        #         num_audio_files = 4
        #     else:
        #         num_audio_files = 6
        for j in range(1,num_audio_files+1):
            # group_data['stimulus_files'].append(['S%02d_%02d' % (i, j), 'segtest%02d_%02d.wav' % (i, j)])
            group_data['stimulus_files'].append(['S%02d_%02d' % (i, j), 'seg%02d_%02d_%02d.mp3' % (batch, i, j)])


        conditions = []
        for clip in group_data['stimulus_files']:
            condition_data = {
                'reference_keys': ['Reference', ],
                'stimulus_keys': (clip[0], clip[0]),
                'evaluation_instructions_html': None
            }
            conditions.append(condition_data)
        group_data['conditions'] = conditions
        test['condition_groups'].append(group_data)
    TESTS.append(test)

CONDITIONS_PER_EVALUATION = len(conditions)
